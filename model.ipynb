{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests \n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service = Service(\"/Users/panavshah/Desktop/Desktop - Panavâ€™s MacBook Pro/chromedriver-mac-x64/chromedriver\")\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# url = \"https://www.tennisabstract.com/cgi-bin/leaders.cgi?f=\"\n",
    "\n",
    "# driver.get(url)\n",
    "# driver.implicitly_wait(10)\n",
    "# html = driver.page_source\n",
    "# print(html)\n",
    "\n",
    "# with open(\"players.html\", \"w\") as f:\n",
    "#     f.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"players.html\") as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "table_players = soup.find(class_='tablesorter')\n",
    "players_a = table_players.find_all('a')\n",
    "players = []\n",
    "ctr = 0\n",
    "for player_a in players_a:\n",
    "    if ctr % 2 == 0:\n",
    "        players.append(player_a.get_text().replace(\" \", \"\"))\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_webscrape_player_data(i, player):\n",
    "#     url = f\"https://www.tennisabstract.com/cgi-bin/player-classic.cgi?p={player}&f=ACareerqq\"\n",
    "#     r = requests.get(url, headers=headers)\n",
    "\n",
    "#     soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "#     with open(f\"players_data/{i}_{player}.html\", \"w\") as file:\n",
    "#         file.write(str(soup))\n",
    "\n",
    "#     # print(script_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, player in enumerate(players):\n",
    "#     get_webscrape_player_data(i, player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_match_data(i):\n",
    "    with open(f\"players_data/{i}_{players[i]}.html\") as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "    scripts = soup.find_all('script')\n",
    "\n",
    "    matchmx = None\n",
    "    for script in scripts:\n",
    "        if 'var matchmx' in script.text:\n",
    "            matchmx_pattern = re.search(r'var matchmx\\s*=\\s*(\\[[\\s\\S]*?\\]);', script.text)\n",
    "            if matchmx_pattern:\n",
    "                matchmx = matchmx_pattern.group(1)\n",
    "                break\n",
    "\n",
    "    matchmx = json.loads(matchmx)\n",
    "\n",
    "    # if matchmx:\n",
    "    #     print(\"Extracted matchmx list:\")\n",
    "    #     print(len(matchmx))\n",
    "    # else:\n",
    "    #     print(\"matchmx variable not found.\")\n",
    "\n",
    "    Rk = []\n",
    "    vRk = []\n",
    "    score = []\n",
    "    for match in matchmx:\n",
    "        try:\n",
    "            Rk_ = int(match[5])\n",
    "            vRk_ = int(match[12])\n",
    "            score_ = 0 if match[4] == 'L' else 1\n",
    "            Rk.append(Rk_)\n",
    "            vRk.append(vRk_)\n",
    "            score.append(score_)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return Rk, vRk, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rk_total, vRk_total, score_total = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rk, vRk, score = get_player_match_data(5)\n",
    "# df = pd.DataFrame({'Rk': Rk, 'vRk': vRk, 'score': score})\n",
    "# df.head()\n",
    "\n",
    "for i in range(0, 50):\n",
    "    Rk, vRk, score = get_player_match_data(i)\n",
    "    Rk_total.extend(Rk)\n",
    "    vRk_total.extend(vRk)\n",
    "    score_total.extend(score)\n",
    "\n",
    "df = pd.DataFrame({'Rk': Rk_total, 'vRk': vRk_total, 'score': score_total})\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>vRk</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26246</th>\n",
       "      <td>1567</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>1567</td>\n",
       "      <td>1279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26248</th>\n",
       "      <td>1567</td>\n",
       "      <td>1332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26249</th>\n",
       "      <td>1567</td>\n",
       "      <td>929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26250</th>\n",
       "      <td>1563</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rk   vRk  score\n",
       "26246  1567   818      0\n",
       "26247  1567  1279      1\n",
       "26248  1567  1332      1\n",
       "26249  1567   929      1\n",
       "26250  1563   658      0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26251, 2), (26251,))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Rk', 'vRk']]\n",
    "y = df['score']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RankComparisonModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RankComparisonModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64)  # Two inputs (ranks)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)  # Output a single percentage value\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  # To output probability (0-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model0 = RankComparisonModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21000, 2]),\n",
       " torch.Size([5251, 2]),\n",
       " torch.Size([21000]),\n",
       " torch.Size([5251]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.to_numpy(), y.to_numpy(), test_size=0.2, random_state=42)\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))  # Ensure it's in the right dtype for torch\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 21\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)  # Adjust batch_size as needed\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)  # No shuffling for test data\n",
    "print(len(train_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3843e-09],\n",
       "        [1.1177e-16],\n",
       "        [1.6130e-11],\n",
       "        [2.8387e-27],\n",
       "        [4.4404e-09],\n",
       "        [0.0000e+00],\n",
       "        [8.0112e-12],\n",
       "        [1.9418e-30],\n",
       "        [2.8700e-09],\n",
       "        [5.2009e-10]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = next(iter(train_dataloader))\n",
    "model0(X_batch)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epsilon = 1e-8\n",
    "        train_acc += (np.abs(y_pred.detach() - y.detach())/(y.detach() + epsilon)).sum().item() / len(y_pred)\n",
    "    \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            epsilon = 1e-8\n",
    "            test_acc += (np.abs(y_pred.detach() - y.detach())/(y.detach() + epsilon)).sum().item() / len(y_pred)\n",
    "        \n",
    "        test_loss += test_loss / len(dataloader)\n",
    "        test_acc += test_acc / len(dataloader)\n",
    "        return test_loss, test_acc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int = 5,):\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "                \"train_acc\": [],\n",
    "                \"test_loss\": [],\n",
    "                \"test_acc\": []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,)\n",
    "\n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:4f} | Test acc: {test_acc:.4f}\")\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)       \n",
    "\n",
    "    return results               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.3339 | Train acc: 6614709424.0000 | Test loss: 6.047122 | Test acc: 153088748750.5867\n",
      "Epoch: 1 | Train loss: 0.2600 | Train acc: 6121593009.4458 | Test loss: 6.540978 | Test acc: 168757049788.8128\n",
      "Epoch: 2 | Train loss: 0.2962 | Train acc: 7388194492.6265 | Test loss: 6.055964 | Test acc: 155096733723.5449\n",
      "Epoch: 3 | Train loss: 0.2697 | Train acc: 6461337111.3253 | Test loss: 5.627082 | Test acc: 141922474346.5504\n",
      "Epoch: 4 | Train loss: 0.2585 | Train acc: 6237976282.9880 | Test loss: 6.037461 | Test acc: 157769965197.2606\n",
      "Epoch: 5 | Train loss: 0.2507 | Train acc: 6021421689.8313 | Test loss: 5.328009 | Test acc: 132398933992.5496\n",
      "Epoch: 6 | Train loss: 0.2503 | Train acc: 6051827562.6024 | Test loss: 5.757585 | Test acc: 150534275979.1203\n",
      "Epoch: 7 | Train loss: 0.2504 | Train acc: 6143794101.2048 | Test loss: 6.292543 | Test acc: 92721778421.8568\n",
      "Epoch: 8 | Train loss: 0.2526 | Train acc: 6167122880.0000 | Test loss: 5.438475 | Test acc: 116183516402.6928\n",
      "Epoch: 9 | Train loss: 0.2428 | Train acc: 5937772181.2048 | Test loss: 5.655422 | Test acc: 106984966493.7085\n",
      "Epoch: 10 | Train loss: 0.2487 | Train acc: 6101737715.0361 | Test loss: 5.323694 | Test acc: 130825046202.4864\n",
      "Epoch: 11 | Train loss: 0.2415 | Train acc: 5964339804.9157 | Test loss: 5.508510 | Test acc: 110452326306.5707\n",
      "Epoch: 12 | Train loss: 0.2460 | Train acc: 6061363361.9277 | Test loss: 5.635942 | Test acc: 106993921480.1658\n",
      "Epoch: 13 | Train loss: 0.2397 | Train acc: 5942502556.1446 | Test loss: 5.872922 | Test acc: 102282368723.0534\n",
      "Epoch: 14 | Train loss: 0.2514 | Train acc: 6229446938.9880 | Test loss: 5.318798 | Test acc: 135142302578.1810\n",
      "Epoch: 15 | Train loss: 0.2448 | Train acc: 6047174323.8554 | Test loss: 6.036487 | Test acc: 98407458178.7452\n",
      "Epoch: 16 | Train loss: 0.2455 | Train acc: 6053420657.3494 | Test loss: 5.210928 | Test acc: 130194057955.9898\n",
      "Epoch: 17 | Train loss: 0.2425 | Train acc: 5978168027.3735 | Test loss: 6.055477 | Test acc: 98843981887.6510\n",
      "Epoch: 18 | Train loss: 0.2515 | Train acc: 6139262086.9398 | Test loss: 6.236653 | Test acc: 94653671017.1545\n",
      "Epoch: 19 | Train loss: 0.2450 | Train acc: 6007856558.2651 | Test loss: 5.273669 | Test acc: 119640764662.7873\n",
      "Epoch: 20 | Train loss: 0.2402 | Train acc: 5971626378.1205 | Test loss: 5.434226 | Test acc: 126144363950.2959\n",
      "Epoch: 21 | Train loss: 0.2440 | Train acc: 6060487333.3976 | Test loss: 5.251511 | Test acc: 134267779158.7292\n",
      "Epoch: 22 | Train loss: 0.2403 | Train acc: 5982592914.9880 | Test loss: 5.255004 | Test acc: 134712870496.9655\n",
      "Epoch: 23 | Train loss: 0.2404 | Train acc: 5969414149.7831 | Test loss: 6.474492 | Test acc: 91710912657.7274\n",
      "Epoch: 24 | Train loss: 0.2470 | Train acc: 6071658492.1446 | Test loss: 5.582164 | Test acc: 147059339734.1243\n",
      "Epoch: 25 | Train loss: 0.2424 | Train acc: 6032769869.6867 | Test loss: 5.756279 | Test acc: 109398823999.2788\n",
      "Epoch: 26 | Train loss: 0.2429 | Train acc: 6024007510.3614 | Test loss: 5.206182 | Test acc: 125138250744.5554\n",
      "Epoch: 27 | Train loss: 0.2389 | Train acc: 5934437560.6747 | Test loss: 6.109676 | Test acc: 99484724668.0683\n",
      "Epoch: 28 | Train loss: 0.2529 | Train acc: 6167313524.4337 | Test loss: 5.305467 | Test acc: 137231510142.3715\n",
      "Epoch: 29 | Train loss: 0.2391 | Train acc: 5954505449.2530 | Test loss: 5.147590 | Test acc: 126540429172.7866\n",
      "Epoch: 30 | Train loss: 0.2406 | Train acc: 5943757541.7831 | Test loss: 5.850661 | Test acc: 103141675905.4424\n",
      "Epoch: 31 | Train loss: 0.2501 | Train acc: 6080870825.0602 | Test loss: 5.488927 | Test acc: 144172183911.9448\n",
      "Epoch: 32 | Train loss: 0.2409 | Train acc: 6024665194.1205 | Test loss: 5.269331 | Test acc: 123686935423.5813\n",
      "Epoch: 33 | Train loss: 0.2416 | Train acc: 6002292220.9157 | Test loss: 6.823021 | Test acc: 86419298282.2246\n",
      "Epoch: 34 | Train loss: 0.2874 | Train acc: 6427867363.4699 | Test loss: 5.614099 | Test acc: 106575678074.2770\n",
      "Epoch: 35 | Train loss: 0.2395 | Train acc: 5893177381.3976 | Test loss: 6.035105 | Test acc: 98735390489.0323\n",
      "Epoch: 36 | Train loss: 0.2410 | Train acc: 5935383722.9880 | Test loss: 5.405950 | Test acc: 141260696736.0582\n",
      "Epoch: 37 | Train loss: 0.2446 | Train acc: 6081486354.5060 | Test loss: 5.217237 | Test acc: 122075326458.7888\n",
      "Epoch: 38 | Train loss: 0.2378 | Train acc: 5899057050.9880 | Test loss: 5.168905 | Test acc: 121471311225.8117\n",
      "Epoch: 39 | Train loss: 0.2377 | Train acc: 5927804787.4699 | Test loss: 5.228248 | Test acc: 125296159659.1320\n",
      "Epoch: 40 | Train loss: 0.2389 | Train acc: 5967910994.8916 | Test loss: 5.436158 | Test acc: 111850083844.0945\n",
      "Epoch: 41 | Train loss: 0.2376 | Train acc: 5937249497.4458 | Test loss: 5.943757 | Test acc: 101019407635.2628\n",
      "Epoch: 42 | Train loss: 0.2418 | Train acc: 6002195379.2771 | Test loss: 5.144603 | Test acc: 124770680469.4497\n",
      "Epoch: 43 | Train loss: 0.2393 | Train acc: 5977086595.7590 | Test loss: 5.291947 | Test acc: 137451667847.5842\n",
      "Epoch: 44 | Train loss: 0.2362 | Train acc: 5936114567.6145 | Test loss: 5.249301 | Test acc: 135886533704.5845\n",
      "Epoch: 45 | Train loss: 0.2398 | Train acc: 6023036413.6867 | Test loss: 5.849201 | Test acc: 103014225852.0683\n",
      "Epoch: 46 | Train loss: 0.2386 | Train acc: 5966325927.9036 | Test loss: 5.156430 | Test acc: 124819514478.9240\n",
      "Epoch: 47 | Train loss: 0.2374 | Train acc: 5995478231.9392 | Test loss: 5.568596 | Test acc: 147498393150.7205\n",
      "Epoch: 48 | Train loss: 0.2443 | Train acc: 6142591818.0241 | Test loss: 5.477080 | Test acc: 110616957855.5929\n",
      "Epoch: 49 | Train loss: 0.2410 | Train acc: 5976299841.9277 | Test loss: 5.170670 | Test acc: 130620599504.8201\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "model_0 = RankComparisonModel()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "model_0_results = train(model=model_0,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6221]])\n"
     ]
    }
   ],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    print(model_0(torch.tensor([40, 1], dtype=torch.float32).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396876785374215"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
